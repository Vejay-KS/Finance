# -*- coding: utf-8 -*-
"""Finance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14o7teEmFlwvZbLlgNlfm673J7D97VKtT

# **Analysis of Finance dataset**
### Author: Vejaykarthy Srithar
"""

!pip install azure-cli

!az login

# Installs

!pip install psycopg
!pip install python-dotenv
!pip install mplfinance
!pip install --upgrade keras

# For colab ip:
# !curl ifconfig.me

# Environment Variables
import os
import dotenv

dotenv.load_dotenv('/content/.env')

KERAS_BACKEND = os.environ.get('KERAS_BACKEND')
APIKEY = os.environ.get('APIKEY')

# Imports

import requests
import pandas as pd
import matplotlib.pyplot as plt
import mplfinance as mpf

from datetime import datetime
from google.colab import drive

import keras

# Constants

NAME_FUNCTION = 'function='
NAME_APIKEY = '&apikey='
NAME_FROM_SYMBOL = '&from_symbol='
NAME_TO_SYMBOL = '&to_symbol='

VALUE_FUNCTION = 'FX_DAILY'
VALUE_FROM_SYMBOL = 'AUD'
VALUE_TO_SYMBOL = 'USD'

URL_BASE = 'https://www.alphavantage.co/query?'
URL_FX_DAILY = URL_BASE + NAME_FUNCTION + VALUE_FUNCTION + NAME_FROM_SYMBOL + VALUE_FROM_SYMBOL + NAME_TO_SYMBOL + VALUE_TO_SYMBOL + NAME_APIKEY + APIKEY

SERIES = 'Time Series FX (Daily)'
DATE = 'Date'
OPEN = 'Open'
CLOSE = 'Close'
HIGH = 'High'
LOW = 'Low'

PLOT_LEGEND_LOCATION = 'upper right'
PLOT_TITLE = 'Variation of exchange rates for the past 100 days between AUD and USD'
PLOT_TITLE_AR = 'Variation of exchange rates using AutoRegression for the next one month between AUD and USD'
PLOT_TITLE_ARIMA = 'Variation of exchange rates using ARIMA for the next one month between AUD and USD'
PLOT_TITLE_LSTM = 'Variation of exchange rates using LSTM for the next one month between AUD and USD'
PLOT_TITLE_GRU = 'Variation of exchange rates using GRU for the next one month between AUD and USD'

# Get data
r = requests.get(URL_FX_DAILY)
data = r.json()

# Process data
data_list = []
for date in data[SERIES]:
  data[SERIES][date][DATE] = datetime.strptime(date, '%Y-%m-%d').date()
  data_list.append(data[SERIES][date])
df = pd.DataFrame(data_list)
df.columns = [OPEN, HIGH, LOW, CLOSE, DATE]
df = df.set_index(DATE)
df = df.iloc[::-1]
df[OPEN] = df[OPEN].apply(lambda x: float(x))
df[HIGH] = df[HIGH].apply(lambda x: float(x))
df[LOW] = df[LOW].apply(lambda x: float(x))
df[CLOSE] = df[CLOSE].apply(lambda x: float(x))
max_pairs_dict = {OPEN: [df[OPEN].idxmax(),df[OPEN].max()],CLOSE: [df[CLOSE].idxmax(),df[CLOSE].max()], HIGH: [df[HIGH].idxmax(),df[HIGH].max()], LOW: [df[LOW].idxmax(),df[LOW].max()]}
min_pairs_dict = {OPEN: [df[OPEN].idxmin(),df[OPEN].min()],CLOSE: [df[CLOSE].idxmin(),df[CLOSE].min()], HIGH: [df[HIGH].idxmin(),df[HIGH].min()], LOW: [df[LOW].idxmin(),df[LOW].min()]}
high_low_diff = pd.DataFrame(df[HIGH] - df[LOW] > 0.02, columns=['Difference_Threshold_Reached'])

# Statistics
print(df.info())
print(df.describe())

# Visualize
plt.legend(loc=PLOT_LEGEND_LOCATION)
plt.title(PLOT_TITLE)
plt.plot(df.index,df[OPEN],color='blue',label=OPEN,linestyle='solid')
plt.plot(df.index,df[CLOSE],color='red',label=CLOSE,linestyle='dashed')
plt.plot(df.index,df[HIGH],color='green',label=HIGH,linestyle='dotted')
plt.plot(df.index,df[LOW],color='orange',label=LOW,linestyle='dashdot')

plt.plot(max_pairs_dict[OPEN][0], max_pairs_dict[OPEN][1],'bo')
plt.plot(max_pairs_dict[CLOSE][0], max_pairs_dict[CLOSE][1],'ro')
plt.plot(max_pairs_dict[HIGH][0], max_pairs_dict[HIGH][1],'go')
plt.plot(max_pairs_dict[LOW][0], max_pairs_dict[LOW][1],'o', c='orange')
plt.plot(max_pairs_dict[OPEN][0], max_pairs_dict[OPEN][1],'bo')
plt.plot(max_pairs_dict[CLOSE][0], max_pairs_dict[CLOSE][1],'ro')
plt.plot(max_pairs_dict[HIGH][0], max_pairs_dict[HIGH][1],'go')
plt.plot(max_pairs_dict[LOW][0], max_pairs_dict[LOW][1],'o',c='orange')

plt.plot(min_pairs_dict[OPEN][0], min_pairs_dict[OPEN][1],'bo')
plt.plot(min_pairs_dict[CLOSE][0], min_pairs_dict[CLOSE][1],'ro')
plt.plot(min_pairs_dict[HIGH][0], min_pairs_dict[HIGH][1],'go')
plt.plot(min_pairs_dict[LOW][0], min_pairs_dict[LOW][1],'o', c='orange')
plt.plot(min_pairs_dict[OPEN][0], min_pairs_dict[OPEN][1],'bo')
plt.plot(min_pairs_dict[CLOSE][0], min_pairs_dict[CLOSE][1],'ro')
plt.plot(min_pairs_dict[HIGH][0], min_pairs_dict[HIGH][1],'go')
plt.plot(min_pairs_dict[LOW][0], min_pairs_dict[LOW][1],'o', c='orange')

plt.plot(high_low_diff[high_low_diff['Difference_Threshold_Reached'] == True].index, df[HIGH][high_low_diff['Difference_Threshold_Reached'] == True], color='black', marker='*', markersize=10)

# Candle plot

# df.index = pd.DatetimeIndex(df.index)
# mpf.plot(df, type='candle', volume=False)

# Create DB connection
import psycopg
from get_conn import get_connection_uri

DBHOST = os.environ.get('DBHOST')
DBNAME = os.environ.get('DBNAME')
DBUSER = os.environ.get('DBUSER')
DBPASSWORD = os.environ.get('DBPASSWORD')
SSLMODE = os.environ.get('SSLMODE')

conn_string = get_connection_uri(DBHOST,DBNAME,DBUSER,DBPASSWORD,SSLMODE)

conn = psycopg.connect(conn_string)
print("Connection established")
cursor = conn.cursor()

# Drop previous results table if it exists
cursor.execute("DROP TABLE IF EXISTS results;")
print("Finished dropping table (if existed)")

# Create results table
cursor.execute("CREATE TABLE results (id serial PRIMARY KEY, model_name VARCHAR(50), model_details  VARCHAR(50), date  DATE, predicted  FLOAT8, actual FLOAT8, error_difference FLOAT8);")
print("Finished creating table")

# Regression

# AutoRegression vs ARIMA (AutoRegressive Integrated Moving Average)

from statsmodels.tsa.arima.model import ARIMA

dates_forecast = pd.date_range(start=df.index[-1], periods=31, freq='D')[1:]
models_names_list = ['AR-model','ARIMA-model1','ARIMA-model2']
models_details_list = ['AR-model-30-0-0','ARIMA-model1-30-1-3','ARIMA-model2-30-2-5']

ar_model = ARIMA(df[LOW], order=(30,0,0)).fit()
forecast = ar_model.forecast(steps=30)

plt.plot(df.index, df[LOW], label="Actual")
plt.plot(dates_forecast, forecast, label="Forecast", linestyle='dashed')
plt.plot(dates_forecast[forecast.idxmin()-101], forecast.min(), color='black', marker='*', markersize=10)
plt.legend()
plt.title(PLOT_TITLE_AR)
plt.show()
cursor.execute("INSERT INTO results (model_name, model_details, date, predicted, actual, error_difference) VALUES (%s, %s, %s, %s, %s, %s);", (models_names_list[0], models_details_list[0], dates_forecast[1], forecast[101], 0, 0))


arima_model1 = ARIMA(df[LOW], order=(30,1,3)).fit()
forecast = arima_model1.forecast(steps=30)

plt.plot(df.index, df[LOW], label="Actual")
plt.plot(dates_forecast, forecast, label="Forecast", linestyle='dotted')
plt.plot(dates_forecast[forecast.idxmin()-101], forecast.min(), color='black', marker='*', markersize=10)
plt.legend()
plt.title(PLOT_TITLE_ARIMA)
plt.show()
cursor.execute("INSERT INTO results (model_name, model_details, date, predicted, actual, error_difference) VALUES (%s, %s, %s, %s, %s, %s);", (models_names_list[1], models_details_list[1], dates_forecast[1], forecast[101], 0, 0))


arima_model2 = ARIMA(df[LOW], order=(30,2,5)).fit()
forecast = arima_model2.forecast(steps=30)

plt.plot(df.index, df[LOW], label="Actual")
plt.plot(dates_forecast, forecast, label="Forecast", linestyle='dotted')
plt.plot(dates_forecast[forecast.idxmin()-101], forecast.min(), color='black', marker='*', markersize=10)
plt.legend()
plt.title(PLOT_TITLE_ARIMA)
plt.show()
cursor.execute("INSERT INTO results (model_name, model_details, date, predicted, actual, error_difference) VALUES (%s, %s, %s, %s, %s, %s);", (models_names_list[2], models_details_list[2], dates_forecast[1], forecast[101], 0, 0))

# LSTM

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import numpy as np

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[LOW].values.reshape(-1, 1))

def create_sequences(data, time_steps=30):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
        y.append(data[i+time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)

X = X.reshape(X.shape[0], X.shape[1], 1)

model1 = Sequential([
    LSTM(100, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    LSTM(50, activation='relu'),
    Dense(1)
])

model2 = Sequential([
    LSTM(100, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    LSTM(50, activation='relu', return_sequences=True),
    LSTM(10, activation='relu'),
    Dense(1)
])

model3 = Sequential([
    LSTM(200, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    LSTM(100, activation='relu'),
    Dense(1)
])

models_list = [model1,model2,model3]
models_names_list = ['LSTM-model1','LSTM-model2','LSTM-model3']
models_details_list = ['LSTM-100-50','LSTM-100-50-10','LSTM-200-100']
k = 0
for model in models_list:
  model.compile(optimizer='adam', loss='mse')
  model.fit(X, y, epochs=50, batch_size=16, verbose=True)

  predicted_values = []
  temp = X[-1]
  for i in range(30):
    last_sequence = temp.reshape(1, time_steps, 1)
    predicted_value = model.predict(last_sequence)
    temp = []
    for j in range(1,30):
      temp.append([last_sequence[0][j][0]])
    temp.append(predicted_value[0])
    temp = np.array([temp])
    predicted_values.append(scaler.inverse_transform(predicted_value)[0][0])
  cursor.execute("INSERT INTO results (model_name, model_details, date, predicted, actual, error_difference) VALUES (%s, %s, %s, %s, %s, %s);", (models_names_list[k], models_details_list[k], dates_forecast[1], predicted_values[0], 0, 0))
  k += 1

  plt.figure(figsize=(10, 5))
  plt.plot(df.index, df[LOW], label="Actual")
  plt.plot(pd.date_range(start=df.index[-1], periods=31, freq='D')[1:], predicted_values, label="Forecast", linestyle='dotted')
  plt.plot(dates_forecast[predicted_values.index(min(predicted_values))], min(predicted_values), color='black', marker='*', markersize=10)
  plt.axvline(df.index[-1], color="red", linestyle="dashed", label="Prediction Point")
  plt.legend()
  plt.title(PLOT_TITLE_LSTM)
  plt.show()

# GRU

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
import numpy as np

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[LOW].values.reshape(-1, 1))

def create_sequences(data, time_steps=30):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
        y.append(data[i+time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(scaled_data, time_steps)

X = X.reshape(X.shape[0], X.shape[1], 1)

model1 = Sequential([
    GRU(100, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    GRU(50, activation='relu'),
    Dense(1)
])

model2 = Sequential([
    GRU(100, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    GRU(50, activation='relu', return_sequences=True),
    GRU(10, activation='relu'),
    Dense(1)
])

model3 = Sequential([
    GRU(200, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),
    GRU(100, activation='relu'),
    Dense(1)
])

models_list = [model1,model2,model3]
models_names_list = ['GRU-model1','GRU-model2','GRU-model3']
models_details_list = ['GRU-100-50','GRU-100-50-10','GRU-200-100']
k = 0
for model in models_list:
  model.compile(optimizer='adam', loss='mse')
  model.fit(X, y, epochs=50, batch_size=16, verbose=True)

  predicted_values = []
  temp = X[-1]
  for i in range(30):
    last_sequence = temp.reshape(1, time_steps, 1)
    predicted_value = model.predict(last_sequence)
    temp = []
    for j in range(1,30):
      temp.append([last_sequence[0][j][0]])
    temp.append(predicted_value[0])
    temp = np.array([temp])
    predicted_values.append(scaler.inverse_transform(predicted_value)[0][0])
  cursor.execute("INSERT INTO results (model_name, model_details, date, predicted, actual, error_difference) VALUES (%s, %s, %s, %s, %s, %s);", (models_names_list[k], models_details_list[k], dates_forecast[1], predicted_values[0], 0, 0))
  k += 1

  plt.figure(figsize=(10, 5))
  plt.plot(df.index, df[LOW], label="Actual")
  plt.plot(pd.date_range(start=df.index[-1], periods=31, freq='D')[1:], predicted_values, label="Forecast", linestyle='dotted')
  plt.plot(dates_forecast[predicted_values.index(min(predicted_values))], min(predicted_values), color='black', marker='*', markersize=10)
  plt.axvline(df.index[-1], color="red", linestyle="dashed", label="Prediction Point")
  plt.legend()
  plt.title(PLOT_TITLE_GRU)
  plt.show()

# Insert some data into the table
print("Inserted rows of data")

# Show all records
cursor.execute('SELECT * FROM results')
results = cursor.fetchall()
for result in results:
  print(result)

# Clean up
conn.commit()
cursor.close()
conn.close()